{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPORT ALL DEPENDENCIES\n",
    "--------------------------\n",
    "Beautiful Soup: Parse HTML objects from web pages\n",
    "Pymongo: Read and write to MongoDB\n",
    "Splinter: Automating browser actions to interact with HTML elements\n",
    "DateTime: Convert dates\n",
    "re: Hack to remove 'rd', 'th', 'st' from date strings\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import time\n",
    "import re\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url = 'https://socialblade.com/youtube/top/50'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'lxml')\n",
    "\n",
    "summary = []\n",
    "ranking = []\n",
    "viewcount = []\n",
    "earnings = []\n",
    "timeline = []\n",
    "\n",
    "def solve(s):                                             \n",
    "    return re.sub(r'(\\d)(st|nd|rd|th)', r'\\1', s)\n",
    "\n",
    "youtuber = soup.find_all('div', style='float: right; width: 900px;')\n",
    "for i in youtuber:\n",
    "    try:\n",
    "        link = i.find_all('a')[2:3]\n",
    "        for i in link:\n",
    "            youtuber_link = i['href']\n",
    "            browser.click_link_by_href(youtuber_link)\n",
    "            html = browser.html\n",
    "            soup = bs(html, 'lxml')\n",
    "\n",
    "            if 'YouTube search results found' or 'YouTube search result found' in soup.text:\n",
    "                browser.back()\n",
    "            else:\n",
    "                name = soup.find_all('h1', style='float: left; font-size: 1.4em; font-weight: bold; color:#333; margin: 0px; padding: 0px; margin-right: 5px;')[0].text\n",
    "\n",
    "                primary_stats = soup.find_all('div', id='YouTubeUserTopInfoBlock')\n",
    "                for i in primary_stats:\n",
    "                    uploads = i.find_all('span', style='font-weight: bold;')[0].text.replace(',', '')\n",
    "                    subscribers = i.find_all('span', style='font-weight: bold;')[1].text.replace(',', '')\n",
    "                    views = i.find_all('span', style='font-weight: bold;')[2].text.replace(',', '')\n",
    "                    category = i.find_all('span', style='font-weight: bold;')[4].text.replace(',', '')\n",
    "                    created = i.find_all('span', style='font-weight: bold;')[5].text.replace(',', '')\n",
    "                    if created == '--':\n",
    "                        created = '1900-01-01'\n",
    "                    else:\n",
    "                        created = datetime.strptime(solve(created), \"%b %d %Y\").strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    print(name)\n",
    "                    print(uploads)\n",
    "                    print(subscribers)\n",
    "                    print(views)\n",
    "                    print(category)\n",
    "                    print(created)\n",
    "   #                 summary.append({'name': name,\n",
    "    #                            'uploads': uploads,\n",
    "   #                             'subscribers': subscribers,\n",
    "     #                           'views': views,\n",
    "   #                             'category': category,\n",
    "   #                             'created': created})\n",
    "\n",
    "                ranking_stats = soup.find_all('div', style='height: 100px; width: 860px; border-bottom: 1px solid #eee;')\n",
    "                for i in ranking_stats:\n",
    "                    grade = i.find_all('p')[0].text\n",
    "                    subscriber_rank = i.find_all('p')[2].text[:-2].replace(',', '')\n",
    "                    view_rank = i.find_all('p')[4].text[:-2].replace(',', '')\n",
    "                    socialblade_rank = i.find_all('p')[6].text[:-2].replace(',', '')\n",
    "\n",
    "                    ranking.append({'name': name,\n",
    "                                'grade': grade,\n",
    "                                'subscriber_rank': subscriber_rank,\n",
    "                                'view_rank': view_rank,\n",
    "                                'socialblade_rank': socialblade_rank})\n",
    "\n",
    "                views_stats = soup.find_all('div', style='height: 70px; width: 860px; border-bottom: 1px solid #eee;')\n",
    "                for i in views_stats:\n",
    "                    views_last30d_count = i.find_all('span', id='afd-header-views-30d')[0].text.replace(',', '').replace('\\n', '')\n",
    "                    subs_last30d_count = i.find_all('span', id='afd-header-subs-30d')[0].text.replace(',', '').replace('\\n', '')\n",
    "\n",
    "                    viewcount.append({'name': name,\n",
    "                                'views_last30d_count': views_last30d_count,\n",
    "                                'subs_last30d_count': subs_last30d_count})\n",
    "\n",
    "                earnings_stats = soup.find_all('div', style='height: 80px; width: 860px;')\n",
    "                for i in earnings_stats:\n",
    "                    min_monthly_earnings = i.find_all('p', style='font-size: 1.4em; color:#41a200; font-weight: 600; padding-top: 20px;')[0].text.split('-')[0].replace('$', '').replace('.', '').replace('K', '00').replace('M', '00000').strip()\n",
    "                    max_monthly_earnings = i.find_all('p', style='font-size: 1.4em; color:#41a200; font-weight: 600; padding-top: 20px;')[0].text.split('-')[1].replace('$', '').replace('.', '').replace('K', '00').replace('M', '00000').strip()\n",
    "                    min_annual_earnings = i.find_all('p', style='font-size: 1.4em; color:#41a200; font-weight: 600; padding-top: 20px;')[1].text.split('-')[0].replace('$', '').replace('.', '').replace('K', '00').replace('M', '00000').strip()\n",
    "                    max_annual_earnings = i.find_all('p', style='font-size: 1.4em; color:#41a200; font-weight: 600; padding-top: 20px;')[1].text.split('-')[1].replace('$', '').replace('.', '').replace('K', '00').replace('M', '00000').strip()\n",
    "\n",
    "                    earnings.append({'name': name,\n",
    "                                'min_monthly_earnings': min_monthly_earnings,\n",
    "                                'max_monthly_earnings': max_monthly_earnings,\n",
    "                                'min_annual_earnings': min_annual_earnings,\n",
    "                                'max_annual_earnings': max_annual_earnings})\n",
    "\n",
    "                timeline_statsA = soup.find_all('div', style='width: 860px; height: 32px; line-height: 32px; background: #f8f8f8;; padding: 0px 20px; color:#444; font-size: 9pt; border-bottom: 1px solid #eee;')\n",
    "                for i in timeline_statsA:\n",
    "                    timeline_dateA = i.find_all('div', style='float: left; width: 95px;')[0].text.replace('\\n', '')\n",
    "                    timeline_subsA = i.find_all('div', style='width: 140px; float: left;')[0].text.replace('\\n', '').replace(',', '')\n",
    "                    timeline_viewsA = i.find_all('div', style='width: 140px; float: left;')[1].text.replace('\\n', '').replace(',', '')\n",
    "\n",
    "                    timeline_min_earningsA = i.find_all('div', style='float: left; width: 165px; height: 30px;')[0].text.split('-')[0].replace('$', '').strip()\n",
    "                    if '.' in timeline_min_earningsA:\n",
    "                        timeline_min_earningsA = timeline_min_earningsA.replace('.', '').replace('K', '00').replace('M', '00000')\n",
    "                    else:\n",
    "                        timeline_min_earningsA = timeline_min_earningsA.replace('K', '000').replace('M', '000000')\n",
    "\n",
    "                    timeline_max_earningsA = i.find_all('div', style='float: left; width: 165px; height: 30px;')[0].text.split('-')[1].replace('$', '').strip()\n",
    "                    if '.' in timeline_max_earningsA:\n",
    "                        timeline_max_earningsA = timeline_max_earningsA.replace('.', '').replace('K', '00').replace('M', '00000')\n",
    "                    else:\n",
    "                        timeline_max_earningsA = timeline_max_earningsA.replace('K', '000').replace('M', '000000')\n",
    "\n",
    "                    timeline.append({'name': name,\n",
    "                                    'date': timeline_dateA,\n",
    "                                   'subscribers': timeline_subsA,\n",
    "                                    'views': timeline_viewsA,\n",
    "                                    'min_earnings': timeline_min_earningsA,\n",
    "                                    'max_earnings': timeline_max_earningsA})\n",
    "\n",
    "                timeline_statsB = soup.find_all('div', style='width: 860px; height: 32px; line-height: 32px; background: #fcfcfc; padding: 0px 20px; color:#444; font-size: 9pt; border-bottom: 1px solid #eee;')\n",
    "                for i in timeline_statsB:\n",
    "                    timeline_dateB = i.find_all('div', style='float: left; width: 95px;')[0].text.replace('\\n', '').strip()\n",
    "                    timeline_subsB = i.find_all('div', style='width: 140px; float: left;')[0].text.replace(',', '').replace('\\n', '').strip()\n",
    "                    timeline_viewsB = i.find_all('div', style='width: 140px; float: left;')[1].text.replace('\\n', '').replace(',', '').strip()\n",
    "\n",
    "                    timeline_min_earningsB = i.find_all('div', style='float: left; width: 165px; height: 30px;')[0].text.split('-')[0].replace('$', '').strip()\n",
    "                    if '.' in timeline_min_earningsB:\n",
    "                        timeline_min_earningsB = timeline_min_earningsB.replace('.', '').replace('K', '00').replace('M', '00000')\n",
    "                    else:\n",
    "                        timeline_min_earningsB = timeline_min_earningsB.replace('K', '000').replace('M', '000000')\n",
    "\n",
    "                    timeline_max_earningsB = i.find_all('div', style='float: left; width: 165px; height: 30px;')[0].text.split('-')[1].replace('$', '').strip()\n",
    "                    if '.' in timeline_max_earningsB:\n",
    "                        timeline_max_earningsB = timeline_max_earningsB.replace('.', '').replace('K', '00').replace('M', '00000')\n",
    "                    else:\n",
    "                        timeline_max_earningsB = timeline_max_earningsB.replace('K', '000').replace('M', '000000')\n",
    "\n",
    "                    timeline.append({'name': name,\n",
    "                                    'date': timeline_dateB,\n",
    "                                    'subscribers': timeline_subsB,\n",
    "                                    'views': timeline_viewsA,\n",
    "                                    'min_earnings': timeline_min_earningsB,\n",
    "                                    'max_earnings': timeline_max_earningsB})\n",
    "\n",
    "\n",
    "                browser.back()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary)\n",
    "views_df = pd.DataFrame(viewcount)\n",
    "ranking_df = pd.DataFrame(ranking)\n",
    "earnings_df = pd.DataFrame(earnings)\n",
    "timeline_df = pd.DataFrame(timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
